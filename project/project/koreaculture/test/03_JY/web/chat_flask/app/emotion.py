import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €, íŒŒì´í”„ë¼ì¸ ì„¤ì •ì„ ì „ì—­ìœ¼ë¡œ
num_labels = 3
model = AutoModelForSequenceClassification.from_pretrained("skt/kogpt2-base-v2", num_labels=num_labels)
device = torch.device('cpu')
model.load_state_dict(torch.load("D:\OneDrive\human\port-folio\personal_project\DLBLM\django\chat_flask\data\model\model_checkpoint.pt", map_location=device))
tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')

pipe = pipeline(
    "text-classification",
    model=model,
    tokenizer=tokenizer,
    device=-1,  # CPUì—ì„œ ì‹¤í–‰
    max_length=512,
    top_k=1,  # ìµœê³  ì ìˆ˜ì˜ ë ˆì´ë¸”ë§Œ ë°˜í™˜
    function_to_apply='softmax'
)

# ë ˆì´ë¸”ì„ í•œêµ­ì–´ë¡œ ë§¤í•‘
label_dict = {'LABEL_0': 'ğŸ¤”ì¤‘ë¦½', 'LABEL_1': 'ğŸ˜ê¸ì •', 'LABEL_2': 'ğŸ˜¤ë¶€ì •'}

def emotion_chk(sentence):
    result = pipe(sentence)
    return label_dict[result[0][0]['label']]
